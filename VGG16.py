
# last 2nd layers to draw

print("6 fine-tuning vgg16:\n\n")
from keras import backend as K
from keras.models import Model, Sequential
#from keras.engine.topology import Layer, InputSpec
from keras.layers import Dense, LSTM, Input , Flatten, Dropout, BatchNormalization
from keras.layers import RepeatVector, Concatenate, Activation, Softmax, Lambda, Reshape
from keras.layers import Dot, Add
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D
from keras import regularizers
from keras.utils import plot_model
from keras.models import model_from_json, load_model
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from keras.applications import VGG16
from keras import optimizers

import pandas as pd
import h5py
import copy
import numpy as np
import random
from PIL import Image

import matplotlib.pyplot as plt
import pdb

import preprocess_crop
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.inception_v3 import preprocess_input



def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)

def build_vgg16(inputs_shape):
    conv_base = VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=inputs_shape)
    '''
    model = Sequential()
    model.add(conv_base)
    model.add(Flatten())
    model.add(Dense(1024, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    '''
    '''
    inputs = Input(shape=inputs_shape)
    convb = conv_base(inputs)
    flat1 = Flatten()(convb)
    dense1 = Dense(1024, activation='relu')(flat1)
    dense2 = Dense(1, activation='sigmoid')(dense1)
    
    model = Model(inputs=inputs, outputs= dense2)
    '''

    flat1 = Flatten()(conv_base.output)
    #x = Dropout(0.8)(flat1)
    dense1 = Dense(1024, activation='relu')(flat1)
    #dense2 = Dense(1, activation='sigmoid')(dense1)
    dense2 = Dense(7, activation='softmax')(dense1)
    model = Model(inputs=conv_base.input, outputs= dense2)
    return model


if __name__ == '__main__':
    #image_size = (600, 450)
    crop_lenght = 500
    crop_width = 450
    crop_size = (crop_lenght, crop_width)
    train_datagen = ImageDataGenerator(
         rescale=1./255,
         rotation_range=30,
         width_shift_range=0.05,
         height_shift_range=0.05,
         shear_range=0.05,
         zoom_range=0.05,
         horizontal_flip=True,
         fill_mode='nearest')
        
    val_datagen = ImageDataGenerator(rescale=1./255)
    test_datagen = ImageDataGenerator(rescale=1./255)

    train_gen = train_datagen.flow_from_directory(
        'train',
        target_size= crop_size,
        batch_size=32,
        class_mode='categorical',
        interpolation = 'lanczos:center')
    #train_gen=crop_generator(train_gen, 256)

    '''
    val_gen = val_datagen.flow_from_directory(
        'val',
        target_size=crop_size,
        batch_size=32,
        class_mode='categorical',
        interpolation = 'lanczos:center')
    #val_gen=crop_generator(val_gen, 256)
    '''
    
    test_gen = test_datagen.flow_from_directory(
        'test',
        target_size=crop_size,
        batch_size=32,
        class_mode='categorical',
        interpolation = 'lanczos:center')
    #test_gen = crop_generator(test_gen, 256)
        
    '''
    test_gen_pred_batches =val_datagen.flow_from_directory(
        'test1',
        target_size=(512, 512),
        batch_size=16,
        class_mode=None)
    test_gen_pred = crop_generator(test_gen_pred_batches, 256)
    '''
    
    #x = next(train_gen)
    #((x0,y0),(x1,y1))=x

    K.clear_session()
    model = build_vgg16(crop_size+(3,))
    model.summary()

    model.trainable = True
    set_trainable = True
    '''
    for layer in model.layers:
        if layer.name == 'block5_conv1':
            set_trainable = True
        if set_trainable:
            layer.trainable = True
        else:
            layer.trainable = False
    '''
    print("len trainable_weights: ")
    #print(model.get_layer('vgg16').trainable_weights)
    print(model.trainable_weights)
    print("\n")

    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
    #model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])

    #pdb.set_trace()
    m_index = 6
    path_model = 'model/model%s.h5' % (m_index)
    callbacks_list = [
        #EarlyStopping(
        #    monitor='acc',
        #    patience=2,
        #    verbose = 1
        #),
        ModelCheckpoint(
            filepath = path_model,
            monitor='acc',
            save_best_only=True,
            verbose = 1
        ),
        ReduceLROnPlateau(
            monitor='loss', 
            factor=0.2,
            patience=5,
            min_lr=1e-5,
            verbose = 1
        )
    ]
    
    historyf = model.fit_generator(
                        train_gen,
                        steps_per_epoch=2,
                        epochs=100,
                        verbose=2,
                        callbacks=callbacks_list,
                        validation_data=None,
                        validation_steps=1)

    results = model.evaluate_generator(test_gen, steps=1)
    print("test:")
    print(results)
    '''
    yp_test = model.predict_generator(test_gen_pred, steps=1)
    yp_test = yp_test.flatten()
    #pdb.set_trace()

    print("****************************")
    print("y_true:")
    y_test = next(test_gen)[1].astype(int)
    print(y_test)
    print("y_predict:")
    yp_temp = yp_test.flatten()
    yp_temp[yp_temp >= 0.5] = 1
    yp_temp[yp_temp < 0.5] = 0
    print(yp_temp.flatten().astype(int))
    #print(yp_test)
    
    
    #pdb.set_trace()
    df = pd.DataFrame({'yp':yp_test.flatten(), 'yt':y_test.flatten()})
    path = 'model/model%s_yp' % m_index
    df.to_csv(path+'.csv', index = False)
    '''
    
    hdict = historyf.history
    hdict.keys()
    loss_train = hdict['loss']
    loss_val = hdict['val_loss']
    acc_train = hdict['acc']
    acc_val = hdict['val_acc']
    df = pd.DataFrame({'loss':loss_train, 'val_loss':loss_val,'acc':acc_train, 'vacc':acc_val})
    #df = pd.DataFrame({'loss':loss_train, 'acc':acc_train})
    path = 'model_vgg/model%s_loss' % m_index
    df.to_csv(path+'.csv', index = False)

    model_saved = load_model(path_model)
    print("\n choosed model:")
    results = model_saved.evaluate_generator(test_gen, steps=1)
    print(results)

    '''
    #print("y_predict_saved_model:")
    yp_test = model_saved.predict_generator(test_gen_pred, steps=1)
    yp_temp = yp_test.flatten()
    yp_temp[yp_temp >= 0.5] = 1
    yp_temp[yp_temp < 0.5] = 0
    print(yp_temp.flatten().astype(int))
    #print(yp_test)
    '''
